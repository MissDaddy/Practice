{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h2>5. NLP (Natural Language Processing) and Corpus Analysis</h2><br><br>\n",
    "\n",
    "<p>NLTK is the best known Python library for NLP. It has over 50 corpora (i.e. electronic collections of texts) and lexicons, some stemmers and algorithms to play with textual data.<p><br>\n",
    "\n",
    "<p> Word frequencies has a wide currency in the digital humanities, including digital textual scholarship. We need to tokenize texts in order to be able to count words and sentences; to count how many words are unique (i.e. occur only once in a text); how many and which words are repetitive; to find lexical patterns called n-grams (i.e. combinations of adjacent words or letters; for example, collocations are a type of n-grams). In text computing, <b><ins>tokenization</ins></b> means breaking a text up into words and sentences. The other useful terms are <b><ins>lemmatization</ins></b> and <b><ins>stemmatization</ins></b>. The two approaches are similar on the surface, but they differ in terms of their purpose and application. <b><ins>Stemmatization</ins></b> runs on stemming algorithms that cut off the end or the beginning of the word, taking into account a list of common prefixes and suffixes that can be found in an inflected word. The following examples show stems derived from the related inflected word forms, e.g. 'studies' is broken into 'studi-es' and gets the stem 'studi', while the word form 'studying' breaks down to 'study-ing' and has the stem 'study'. <b><ins>Lemmatization</ins></b>, on the other hand, relies on the morphological analysis of each word and is sensitive to a language being analyzed. lemmatization involves grouping inflected word forms as one word lemma so that they can analyzed as one word, e.g. word forms <i>run</i>, <i>running</i>, and <i>ran</i>   will be treated as one lemma RUN.</p><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package nltk:\n",
      "\n",
      "NAME\n",
      "    nltk\n",
      "\n",
      "DESCRIPTION\n",
      "    The Natural Language Toolkit (NLTK) is an open source Python library\n",
      "    for Natural Language Processing.  A free online book is available.\n",
      "    (If you use the library for academic research, please cite the book.)\n",
      "    \n",
      "    Steven Bird, Ewan Klein, and Edward Loper (2009).\n",
      "    Natural Language Processing with Python.  O'Reilly Media Inc.\n",
      "    http://nltk.org/book\n",
      "    \n",
      "    @version: 3.4\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    app (package)\n",
      "    book\n",
      "    ccg (package)\n",
      "    chat (package)\n",
      "    chunk (package)\n",
      "    classify (package)\n",
      "    cluster (package)\n",
      "    collections\n",
      "    collocations\n",
      "    compat\n",
      "    corpus (package)\n",
      "    data\n",
      "    decorators\n",
      "    downloader\n",
      "    draw (package)\n",
      "    featstruct\n",
      "    grammar\n",
      "    help\n",
      "    inference (package)\n",
      "    internals\n",
      "    jsontags\n",
      "    lazyimport\n",
      "    lm (package)\n",
      "    metrics (package)\n",
      "    misc (package)\n",
      "    parse (package)\n",
      "    probability\n",
      "    sem (package)\n",
      "    sentiment (package)\n",
      "    stem (package)\n",
      "    tag (package)\n",
      "    tbl (package)\n",
      "    test (package)\n",
      "    text\n",
      "    tgrep\n",
      "    tokenize (package)\n",
      "    toolbox\n",
      "    translate (package)\n",
      "    tree\n",
      "    treeprettyprinter\n",
      "    treetransforms\n",
      "    twitter (package)\n",
      "    util\n",
      "    wsd\n",
      "\n",
      "SUBMODULES\n",
      "    agreement\n",
      "    aline\n",
      "    api\n",
      "    association\n",
      "    bleu_score\n",
      "    bllip\n",
      "    boxer\n",
      "    brill\n",
      "    brill_trainer\n",
      "    casual\n",
      "    chart\n",
      "    cistem\n",
      "    confusionmatrix\n",
      "    corenlp\n",
      "    crf\n",
      "    decisiontree\n",
      "    dependencygraph\n",
      "    discourse\n",
      "    distance\n",
      "    drt\n",
      "    earleychart\n",
      "    evaluate\n",
      "    featurechart\n",
      "    glue\n",
      "    hmm\n",
      "    hunpos\n",
      "    ibm1\n",
      "    ibm2\n",
      "    ibm3\n",
      "    ibm4\n",
      "    ibm5\n",
      "    ibm_model\n",
      "    isri\n",
      "    lancaster\n",
      "    lfg\n",
      "    linearlogic\n",
      "    logic\n",
      "    mace\n",
      "    malt\n",
      "    mapping\n",
      "    maxent\n",
      "    megam\n",
      "    mwe\n",
      "    naivebayes\n",
      "    nonprojectivedependencyparser\n",
      "    paice\n",
      "    pchart\n",
      "    perceptron\n",
      "    porter\n",
      "    positivenaivebayes\n",
      "    projectivedependencyparser\n",
      "    prover9\n",
      "    punkt\n",
      "    recursivedescent\n",
      "    regexp\n",
      "    relextract\n",
      "    repp\n",
      "    resolution\n",
      "    ribes_score\n",
      "    rslp\n",
      "    rte_classify\n",
      "    scikitlearn\n",
      "    scores\n",
      "    segmentation\n",
      "    senna\n",
      "    sequential\n",
      "    sexpr\n",
      "    shiftreduce\n",
      "    simple\n",
      "    snowball\n",
      "    spearman\n",
      "    stack_decoder\n",
      "    stanford\n",
      "    stanford_segmenter\n",
      "    tableau\n",
      "    tadm\n",
      "    textcat\n",
      "    texttiling\n",
      "    tnt\n",
      "    toktok\n",
      "    transitionparser\n",
      "    treebank\n",
      "    viterbi\n",
      "    weka\n",
      "    wordnet\n",
      "\n",
      "FUNCTIONS\n",
      "    demo()\n",
      "        # FIXME:  override any accidentally imported demo, see https://github.com/nltk/nltk/issues/2116\n",
      "\n",
      "DATA\n",
      "    RUS_PICKLE = 'taggers/averaged_perceptron_tagger_ru/averaged_perceptro...\n",
      "    SLASH = *slash*\n",
      "    TYPE = *type*\n",
      "    __author_email__ = 'stevenbird1@gmail.com'\n",
      "    __classifiers__ = ['Development Status :: 5 - Production/Stable', 'Int...\n",
      "    __copyright__ = 'Copyright (C) 2001-2019 NLTK Project.\\n\\nDistribut......\n",
      "    __keywords__ = ['NLP', 'CL', 'natural language processing', 'computati...\n",
      "    __license__ = 'Apache License, Version 2.0'\n",
      "    __longdescr__ = 'The Natural Language Toolkit (NLTK) is a Python ... p...\n",
      "    __maintainer__ = 'Steven Bird, Edward Loper, Ewan Klein'\n",
      "    __maintainer_email__ = 'stevenbird1@gmail.com'\n",
      "    __url__ = 'http://nltk.org/'\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    app = <LazyModule 'nltk.nltk.app'>\n",
      "    chat = <LazyModule 'nltk.nltk.chat'>\n",
      "    class_types = (<class 'type'>,)\n",
      "    corpus = <LazyModule 'nltk.nltk.corpus'>\n",
      "    improved_close_quote_regex = re.compile('([»”’])')\n",
      "    improved_open_quote_regex = re.compile('([«“‘„]|[`]+)')\n",
      "    improved_open_single_quote_regex = re.compile(\"(?i)(\\\\')(?!re|ve|ll|m|...\n",
      "    improved_punct_regex = re.compile('([^\\\\.])(\\\\.)([\\\\]\\\\)}>\"\\\\\\'»”’ ]*)...\n",
      "    infile = <_io.TextIOWrapper name='C:\\\\Users\\\\1veln\\\\Anaco...kages\\\\nlt...\n",
      "    json_tags = {'!nltk.tag.BrillTagger': <class 'nltk.tag.brill.BrillTagg...\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "    string_types = (<class 'str'>,)\n",
      "    toolbox = <LazyModule 'nltk.nltk.toolbox'>\n",
      "    version_file = r'C:\\Users\\1veln\\Anaconda3\\lib\\site-packages\\nltk\\VERSI...\n",
      "    version_info = sys.version_info(major=3, minor=7, micro=3, releaseleve...\n",
      "\n",
      "VERSION\n",
      "    3.4\n",
      "\n",
      "AUTHOR\n",
      "    Steven Bird, Edward Loper, Ewan Klein\n",
      "\n",
      "FILE\n",
      "    c:\\users\\1veln\\anaconda3\\lib\\site-packages\\nltk\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# You can check it in the Python working environment if a specific third-party package is installed as follows:\n",
    "\n",
    "help('nltk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Alternatively, you may print out the entire list of all Python packages already installed on your computer.\n",
    "#### You can do so by opening Anaconda Prompt command-line window and typing 'pip freeze' or 'pip list' as in the visual below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pipfreeze.JPG) \n",
    "\n",
    "#### If help() function returns the message that no documentation is found or the pip freeze command gives a list with no item, then you need to install that library with the pip package manager. \n",
    "#### pip is specific to Python packages. You can run its commands in Windows cmd (or Mac terminal) OR Anaconda Prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and download nltk  \n",
    "\n",
    "Open Windows cmd (or Mac terminal) OR  Anadconda Prompt, and install the nltk package with  the code <em>pip install -U nltk</em>\n",
    "\n",
    " \n",
    "![title](pip install nltk.JPG) \n",
    "\n",
    "Then run the Python interpreter and write the code below to import and download NLTK packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With the import statement bring the nltk package into the working environment of Python.\n",
    "\n",
    "import nltk\n",
    "nltk.download()\n",
    "\n",
    "# The NLTK downloader will appear as a pop-up window - click the 'Download' button if you want all things.\n",
    "\n",
    "# Alternatively, you may select only some things from the list it offers and then click 'Download'.\n",
    "\n",
    "# Once the download is complete, close the pop-up window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pop-up window nltk downloader window looks as below:\n",
    "\n",
    "![title](nltkdownloader.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "# brown is the module that contains the Brown Corpus which is annotated with part-of-speech tags. \n",
    "# It contains 500 samples of English-language texts.\n",
    "# In total, it's roughly one million words, compiled from works published in the United States in 1961.\n",
    "\n",
    "\n",
    "# Extract words with the words() method of brown module\n",
    "brown.words()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also import a collection of literary texts from the Gutenberg Project (https://www.gutenberg.org/)\n",
    "# Project Gutenberg is a library of over 60,000 free eBooks of different genre.\n",
    "\n",
    "from nltk.corpus import gutenberg as gt\n",
    "\n",
    "# The following command will print out the list of texts available in the Brown corpus.\n",
    "\n",
    "gt.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[', 'Poems', 'by', 'William', 'Blake', '1789', ']', ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As above, use words() to extract words from the collection of William Blake's poems.\n",
    "\n",
    "# Pass the title of William Blake's collection as an argument.\n",
    "\n",
    "blake = gt.words('blake-poems.txt')\n",
    "\n",
    "blake\n",
    "\n",
    "# It will read in the entire collection though you won't see it all in the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8354"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's count how many words this collection contains.\n",
    "\n",
    "len(blake)\n",
    "\n",
    "# You can embed one function inside another  as below. Instead of taking one step at a time, you may take two steps, e.g.\n",
    "\n",
    "# len(gt.words('blake-poems.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Poems',\n",
       " 'by',\n",
       " 'William',\n",
       " 'Blake',\n",
       " '1789',\n",
       " ']',\n",
       " 'SONGS',\n",
       " 'OF',\n",
       " 'INNOCENCE',\n",
       " 'AND',\n",
       " 'OF',\n",
       " 'EXPERIENCE',\n",
       " 'and',\n",
       " 'THE',\n",
       " 'BOOK',\n",
       " 'of',\n",
       " 'THEL',\n",
       " 'SONGS',\n",
       " 'OF',\n",
       " 'INNOCENCE',\n",
       " 'INTRODUCTION',\n",
       " 'Piping',\n",
       " 'down',\n",
       " 'the',\n",
       " 'valleys',\n",
       " 'wild',\n",
       " ',',\n",
       " 'Piping',\n",
       " 'songs',\n",
       " 'of',\n",
       " 'pleasant',\n",
       " 'glee',\n",
       " ',',\n",
       " 'On',\n",
       " 'a',\n",
       " 'cloud',\n",
       " 'I',\n",
       " 'saw',\n",
       " 'a',\n",
       " 'child',\n",
       " ',',\n",
       " 'And',\n",
       " 'he',\n",
       " 'laughing',\n",
       " 'said',\n",
       " 'to',\n",
       " 'me',\n",
       " ':',\n",
       " '\"',\n",
       " 'Pipe',\n",
       " 'a',\n",
       " 'song',\n",
       " 'about',\n",
       " 'a',\n",
       " 'Lamb',\n",
       " '!\"',\n",
       " 'So',\n",
       " 'I',\n",
       " 'piped',\n",
       " 'with',\n",
       " 'merry',\n",
       " 'cheer',\n",
       " '.',\n",
       " '\"',\n",
       " 'Piper',\n",
       " ',',\n",
       " 'pipe',\n",
       " 'that',\n",
       " 'song',\n",
       " 'again',\n",
       " ';\"',\n",
       " 'So',\n",
       " 'I',\n",
       " 'piped',\n",
       " ':',\n",
       " 'he',\n",
       " 'wept',\n",
       " 'to',\n",
       " 'hear',\n",
       " '.',\n",
       " '\"',\n",
       " 'Drop',\n",
       " 'thy',\n",
       " 'pipe',\n",
       " ',',\n",
       " 'thy',\n",
       " 'happy',\n",
       " 'pipe',\n",
       " ';',\n",
       " 'Sing',\n",
       " 'thy',\n",
       " 'songs',\n",
       " 'of',\n",
       " 'happy',\n",
       " 'cheer',\n",
       " ':!\"',\n",
       " 'So',\n",
       " 'I',\n",
       " 'sang',\n",
       " 'the',\n",
       " 'same',\n",
       " 'again',\n",
       " ',',\n",
       " 'While',\n",
       " 'he',\n",
       " 'wept',\n",
       " 'with',\n",
       " 'joy',\n",
       " 'to',\n",
       " 'hear',\n",
       " '.',\n",
       " '\"',\n",
       " 'Piper',\n",
       " ',',\n",
       " 'sit',\n",
       " 'thee',\n",
       " 'down',\n",
       " 'and',\n",
       " 'write',\n",
       " 'In',\n",
       " 'a',\n",
       " 'book',\n",
       " ',',\n",
       " 'that',\n",
       " 'all',\n",
       " 'may',\n",
       " 'read',\n",
       " '.\"',\n",
       " 'So',\n",
       " 'he',\n",
       " 'vanish',\n",
       " \"'\",\n",
       " 'd',\n",
       " 'from',\n",
       " 'my',\n",
       " 'sight',\n",
       " ';',\n",
       " 'And',\n",
       " 'I',\n",
       " 'pluck',\n",
       " \"'\",\n",
       " 'd',\n",
       " 'a',\n",
       " 'hollow',\n",
       " 'reed',\n",
       " ',',\n",
       " 'And',\n",
       " 'I',\n",
       " 'made',\n",
       " 'a',\n",
       " 'rural',\n",
       " 'pen',\n",
       " ',',\n",
       " 'And',\n",
       " 'I',\n",
       " 'stain',\n",
       " \"'\",\n",
       " 'd',\n",
       " 'the',\n",
       " 'water',\n",
       " 'clear',\n",
       " ',',\n",
       " 'And',\n",
       " 'I',\n",
       " 'wrote',\n",
       " 'my',\n",
       " 'happy',\n",
       " 'songs',\n",
       " 'Every',\n",
       " 'child',\n",
       " 'may',\n",
       " 'joy',\n",
       " 'to',\n",
       " 'hear',\n",
       " '.',\n",
       " 'THE',\n",
       " 'SHEPHERD',\n",
       " 'How',\n",
       " 'sweet',\n",
       " 'is',\n",
       " 'the',\n",
       " 'Shepherd',\n",
       " \"'\",\n",
       " 's',\n",
       " 'sweet',\n",
       " 'lot',\n",
       " '!',\n",
       " 'From',\n",
       " 'the',\n",
       " 'morn',\n",
       " 'to',\n",
       " 'the',\n",
       " 'evening',\n",
       " 'he',\n",
       " 'stays',\n",
       " ';',\n",
       " 'He',\n",
       " 'shall',\n",
       " 'follow',\n",
       " 'his',\n",
       " 'sheep',\n",
       " 'all',\n",
       " 'the',\n",
       " 'day',\n",
       " ',',\n",
       " 'And',\n",
       " 'his',\n",
       " 'tongue',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'filled',\n",
       " 'with',\n",
       " 'praise',\n",
       " '.',\n",
       " 'For',\n",
       " 'he',\n",
       " 'hears',\n",
       " 'the',\n",
       " 'lambs',\n",
       " \"'\",\n",
       " 'innocent',\n",
       " 'call',\n",
       " ',',\n",
       " 'And',\n",
       " 'he',\n",
       " 'hears',\n",
       " 'the',\n",
       " 'ewes',\n",
       " \"'\",\n",
       " 'tender',\n",
       " 'reply',\n",
       " ';',\n",
       " 'He',\n",
       " 'is',\n",
       " 'watching',\n",
       " 'while',\n",
       " 'they',\n",
       " 'are',\n",
       " 'in',\n",
       " 'peace',\n",
       " ',',\n",
       " 'For',\n",
       " 'they',\n",
       " 'know',\n",
       " 'when',\n",
       " 'their',\n",
       " 'Shepherd',\n",
       " 'is',\n",
       " 'nigh',\n",
       " '.',\n",
       " 'THE',\n",
       " 'ECHOING',\n",
       " 'GREEN',\n",
       " 'The',\n",
       " 'sun',\n",
       " 'does',\n",
       " 'arise',\n",
       " ',',\n",
       " 'And',\n",
       " 'make',\n",
       " 'happy',\n",
       " 'the',\n",
       " 'skies',\n",
       " ';',\n",
       " 'The',\n",
       " 'merry',\n",
       " 'bells',\n",
       " 'ring',\n",
       " 'To',\n",
       " 'welcome',\n",
       " 'the',\n",
       " 'Spring',\n",
       " ';',\n",
       " 'The',\n",
       " 'skylark',\n",
       " 'and',\n",
       " 'thrush',\n",
       " ',',\n",
       " 'The',\n",
       " 'birds',\n",
       " 'of',\n",
       " 'the',\n",
       " 'bush',\n",
       " ',',\n",
       " 'Sing',\n",
       " 'louder',\n",
       " 'around',\n",
       " 'To',\n",
       " 'the',\n",
       " 'bells',\n",
       " \"'\",\n",
       " 'cheerful',\n",
       " 'sound',\n",
       " ';',\n",
       " 'While',\n",
       " 'our',\n",
       " 'sports',\n",
       " 'shall',\n",
       " 'be',\n",
       " 'seen',\n",
       " 'On',\n",
       " 'the',\n",
       " 'echoing',\n",
       " 'Green',\n",
       " '.',\n",
       " 'Old',\n",
       " 'John',\n",
       " ',',\n",
       " 'with',\n",
       " 'white',\n",
       " 'hair',\n",
       " ',',\n",
       " 'Does',\n",
       " 'laugh',\n",
       " 'away',\n",
       " 'care',\n",
       " ',',\n",
       " 'Sitting',\n",
       " 'under',\n",
       " 'the',\n",
       " 'oak',\n",
       " ',',\n",
       " 'Among',\n",
       " 'the',\n",
       " 'old',\n",
       " 'folk',\n",
       " '.',\n",
       " 'They',\n",
       " 'laugh',\n",
       " 'at',\n",
       " 'our',\n",
       " 'play',\n",
       " ',',\n",
       " 'And',\n",
       " 'soon',\n",
       " 'they',\n",
       " 'all',\n",
       " 'say',\n",
       " ',',\n",
       " '\"',\n",
       " 'Such',\n",
       " ',',\n",
       " 'such',\n",
       " 'were',\n",
       " 'the',\n",
       " 'joys',\n",
       " 'When',\n",
       " 'we',\n",
       " 'all',\n",
       " '--',\n",
       " 'girls',\n",
       " 'and',\n",
       " 'boys',\n",
       " '--',\n",
       " 'In',\n",
       " 'our',\n",
       " 'youth',\n",
       " '-',\n",
       " 'time',\n",
       " 'were',\n",
       " 'seen',\n",
       " 'On',\n",
       " 'the',\n",
       " 'echoing',\n",
       " 'Green',\n",
       " '.\"',\n",
       " 'Till',\n",
       " 'the',\n",
       " 'little',\n",
       " 'ones',\n",
       " ',',\n",
       " 'weary',\n",
       " ',',\n",
       " 'No',\n",
       " 'more',\n",
       " 'can',\n",
       " 'be',\n",
       " 'merry',\n",
       " ':',\n",
       " 'The',\n",
       " 'sun',\n",
       " 'does',\n",
       " 'descend',\n",
       " ',',\n",
       " 'And',\n",
       " 'our',\n",
       " 'sports',\n",
       " 'have',\n",
       " 'an',\n",
       " 'end',\n",
       " '.',\n",
       " 'Round',\n",
       " 'the',\n",
       " 'laps',\n",
       " 'of',\n",
       " 'their',\n",
       " 'mothers',\n",
       " 'Many',\n",
       " 'sisters',\n",
       " 'and',\n",
       " 'brothers',\n",
       " ',',\n",
       " 'Like',\n",
       " 'birds',\n",
       " 'in',\n",
       " 'their',\n",
       " 'nest',\n",
       " ',',\n",
       " 'Are',\n",
       " 'ready',\n",
       " 'for',\n",
       " 'rest',\n",
       " ',',\n",
       " 'And',\n",
       " 'sport',\n",
       " 'no',\n",
       " 'more',\n",
       " 'seen',\n",
       " 'On',\n",
       " 'the',\n",
       " 'darkening',\n",
       " 'green',\n",
       " '.',\n",
       " 'THE',\n",
       " 'LAMB',\n",
       " 'Little',\n",
       " 'Lamb',\n",
       " ',',\n",
       " 'who',\n",
       " 'make',\n",
       " 'thee',\n",
       " 'Dost',\n",
       " 'thou',\n",
       " 'know',\n",
       " 'who',\n",
       " 'made',\n",
       " 'thee',\n",
       " ',',\n",
       " 'Gave',\n",
       " 'thee',\n",
       " 'life',\n",
       " ',',\n",
       " 'and',\n",
       " 'bid',\n",
       " 'thee',\n",
       " 'feed',\n",
       " 'By',\n",
       " 'the',\n",
       " 'stream',\n",
       " 'and',\n",
       " 'o',\n",
       " \"'\",\n",
       " 'er',\n",
       " 'the',\n",
       " 'mead',\n",
       " ';',\n",
       " 'Gave',\n",
       " 'thee',\n",
       " 'clothing',\n",
       " 'of',\n",
       " 'delight',\n",
       " ',',\n",
       " 'Softest',\n",
       " 'clothing',\n",
       " ',',\n",
       " 'wolly',\n",
       " ',',\n",
       " 'bright',\n",
       " ';',\n",
       " 'Gave',\n",
       " 'thee',\n",
       " 'such',\n",
       " 'a',\n",
       " 'tender',\n",
       " 'voice',\n",
       " ',',\n",
       " 'Making',\n",
       " 'all',\n",
       " 'the',\n",
       " 'vales',\n",
       " 'rejoice',\n",
       " '?',\n",
       " 'Little',\n",
       " 'Lamb',\n",
       " ',',\n",
       " 'who',\n",
       " 'made',\n",
       " 'thee',\n",
       " '?',\n",
       " 'Dost',\n",
       " 'thou',\n",
       " 'know',\n",
       " 'who',\n",
       " 'made',\n",
       " 'thee',\n",
       " '?',\n",
       " 'Little',\n",
       " 'Lamb',\n",
       " ',',\n",
       " 'I',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'tell',\n",
       " 'thee',\n",
       " ';',\n",
       " 'Little',\n",
       " 'Lamb',\n",
       " ',',\n",
       " 'I',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'tell',\n",
       " 'thee',\n",
       " ':',\n",
       " 'He',\n",
       " 'is',\n",
       " 'called',\n",
       " 'by',\n",
       " 'thy',\n",
       " 'name',\n",
       " ',',\n",
       " 'For',\n",
       " 'He',\n",
       " 'calls',\n",
       " 'Himself',\n",
       " 'a',\n",
       " 'Lamb',\n",
       " 'He',\n",
       " 'is',\n",
       " 'meek',\n",
       " ',',\n",
       " 'and',\n",
       " 'He',\n",
       " 'is',\n",
       " 'mild',\n",
       " ',',\n",
       " 'He',\n",
       " 'became',\n",
       " 'a',\n",
       " 'little',\n",
       " 'child',\n",
       " '.',\n",
       " 'I',\n",
       " 'a',\n",
       " 'child',\n",
       " ',',\n",
       " 'and',\n",
       " 'thou',\n",
       " 'a',\n",
       " 'lamb',\n",
       " ',',\n",
       " 'We',\n",
       " 'are',\n",
       " 'called',\n",
       " 'by',\n",
       " 'His',\n",
       " 'name',\n",
       " '.',\n",
       " 'Little',\n",
       " 'Lamb',\n",
       " ',',\n",
       " 'God',\n",
       " 'bless',\n",
       " 'thee',\n",
       " '!',\n",
       " 'Little',\n",
       " 'Lamb',\n",
       " ',',\n",
       " 'God',\n",
       " 'bless',\n",
       " 'thee',\n",
       " '!',\n",
       " 'THE',\n",
       " 'LITTLE',\n",
       " 'BLACK',\n",
       " 'BOY',\n",
       " 'My',\n",
       " 'mother',\n",
       " 'bore',\n",
       " 'me',\n",
       " 'in',\n",
       " 'the',\n",
       " 'southern',\n",
       " 'wild',\n",
       " ',',\n",
       " 'And',\n",
       " 'I',\n",
       " 'am',\n",
       " 'black',\n",
       " ',',\n",
       " 'but',\n",
       " 'oh',\n",
       " 'my',\n",
       " 'soul',\n",
       " 'is',\n",
       " 'white',\n",
       " '!',\n",
       " 'White',\n",
       " 'as',\n",
       " 'an',\n",
       " 'angel',\n",
       " 'is',\n",
       " 'the',\n",
       " 'English',\n",
       " 'child',\n",
       " ',',\n",
       " 'But',\n",
       " 'I',\n",
       " 'am',\n",
       " 'black',\n",
       " ',',\n",
       " 'as',\n",
       " 'if',\n",
       " 'bereaved',\n",
       " 'of',\n",
       " 'light',\n",
       " '.',\n",
       " 'My',\n",
       " 'mother',\n",
       " 'taught',\n",
       " 'me',\n",
       " 'underneath',\n",
       " 'a',\n",
       " 'tree',\n",
       " ',',\n",
       " 'And',\n",
       " ',',\n",
       " 'sitting',\n",
       " 'down',\n",
       " 'before',\n",
       " 'the',\n",
       " 'heat',\n",
       " 'of',\n",
       " 'day',\n",
       " ',',\n",
       " 'She',\n",
       " 'took',\n",
       " 'me',\n",
       " 'on',\n",
       " 'her',\n",
       " 'lap',\n",
       " 'and',\n",
       " 'kissed',\n",
       " 'me',\n",
       " ',',\n",
       " 'And',\n",
       " ',',\n",
       " 'pointed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'east',\n",
       " ',',\n",
       " 'began',\n",
       " 'to',\n",
       " 'say',\n",
       " ':',\n",
       " '\"',\n",
       " 'Look',\n",
       " 'on',\n",
       " 'the',\n",
       " 'rising',\n",
       " 'sun',\n",
       " ':',\n",
       " 'there',\n",
       " 'God',\n",
       " 'does',\n",
       " 'live',\n",
       " ',',\n",
       " 'And',\n",
       " 'gives',\n",
       " 'His',\n",
       " 'light',\n",
       " ',',\n",
       " 'and',\n",
       " 'gives',\n",
       " 'His',\n",
       " 'heat',\n",
       " 'away',\n",
       " ',',\n",
       " 'And',\n",
       " 'flowers',\n",
       " 'and',\n",
       " 'trees',\n",
       " 'and',\n",
       " 'beasts',\n",
       " 'and',\n",
       " 'men',\n",
       " 'receive',\n",
       " 'Comfort',\n",
       " 'in',\n",
       " 'morning',\n",
       " ',',\n",
       " 'joy',\n",
       " 'in',\n",
       " 'the',\n",
       " 'noonday',\n",
       " '.',\n",
       " '\"',\n",
       " 'And',\n",
       " 'we',\n",
       " 'are',\n",
       " 'put',\n",
       " 'on',\n",
       " 'earth',\n",
       " 'a',\n",
       " 'little',\n",
       " 'space',\n",
       " ',',\n",
       " 'That',\n",
       " 'we',\n",
       " 'may',\n",
       " 'learn',\n",
       " 'to',\n",
       " 'bear',\n",
       " 'the',\n",
       " 'beams',\n",
       " 'of',\n",
       " 'love',\n",
       " 'And',\n",
       " 'these',\n",
       " 'black',\n",
       " 'bodies',\n",
       " 'and',\n",
       " 'this',\n",
       " 'sunburnt',\n",
       " 'face',\n",
       " 'Is',\n",
       " 'but',\n",
       " 'a',\n",
       " 'cloud',\n",
       " ',',\n",
       " 'and',\n",
       " 'like',\n",
       " 'a',\n",
       " 'shady',\n",
       " 'grove',\n",
       " '.',\n",
       " '\"',\n",
       " 'For',\n",
       " 'when',\n",
       " 'our',\n",
       " 'souls',\n",
       " 'have',\n",
       " 'learn',\n",
       " \"'\",\n",
       " 'd',\n",
       " 'the',\n",
       " 'heat',\n",
       " 'to',\n",
       " 'bear',\n",
       " ',',\n",
       " 'The',\n",
       " 'cloud',\n",
       " 'will',\n",
       " 'vanish',\n",
       " ',',\n",
       " 'we',\n",
       " 'shall',\n",
       " 'hear',\n",
       " 'His',\n",
       " 'voice',\n",
       " ',',\n",
       " 'Saying',\n",
       " ',',\n",
       " \"'\",\n",
       " 'Come',\n",
       " 'out',\n",
       " 'from',\n",
       " 'the',\n",
       " 'grove',\n",
       " ',',\n",
       " 'my',\n",
       " 'love',\n",
       " 'and',\n",
       " 'care',\n",
       " 'And',\n",
       " 'round',\n",
       " 'my',\n",
       " 'golden',\n",
       " 'tent',\n",
       " 'like',\n",
       " 'lambs',\n",
       " 'rejoice',\n",
       " '\\',\"',\n",
       " 'Thus',\n",
       " 'did',\n",
       " 'my',\n",
       " 'mother',\n",
       " 'say',\n",
       " ',',\n",
       " 'and',\n",
       " 'kissed',\n",
       " 'me',\n",
       " ';',\n",
       " 'And',\n",
       " 'thus',\n",
       " 'I',\n",
       " 'say',\n",
       " 'to',\n",
       " 'little',\n",
       " 'English',\n",
       " 'boy',\n",
       " '.',\n",
       " 'When',\n",
       " 'I',\n",
       " 'from',\n",
       " 'black',\n",
       " 'and',\n",
       " 'he',\n",
       " 'from',\n",
       " 'white',\n",
       " 'cloud',\n",
       " 'free',\n",
       " ',',\n",
       " 'And',\n",
       " 'round',\n",
       " 'the',\n",
       " 'tent',\n",
       " 'of',\n",
       " 'God',\n",
       " 'like',\n",
       " 'lambs',\n",
       " 'we',\n",
       " 'joy',\n",
       " 'I',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'shade',\n",
       " 'him',\n",
       " 'from',\n",
       " 'the',\n",
       " 'heat',\n",
       " 'till',\n",
       " 'he',\n",
       " 'can',\n",
       " 'bear',\n",
       " 'To',\n",
       " 'lean',\n",
       " 'in',\n",
       " 'joy',\n",
       " 'upon',\n",
       " 'our',\n",
       " 'Father',\n",
       " \"'\",\n",
       " 's',\n",
       " 'knee',\n",
       " ';',\n",
       " 'And',\n",
       " 'then',\n",
       " 'I',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'stand',\n",
       " 'and',\n",
       " 'stroke',\n",
       " 'his',\n",
       " 'silver',\n",
       " 'hair',\n",
       " ',',\n",
       " 'And',\n",
       " 'be',\n",
       " 'like',\n",
       " 'him',\n",
       " ',',\n",
       " 'and',\n",
       " 'he',\n",
       " 'will',\n",
       " 'then',\n",
       " 'love',\n",
       " 'me',\n",
       " '.',\n",
       " 'THE',\n",
       " 'BLOSSOM',\n",
       " 'Merry',\n",
       " ',',\n",
       " 'merry',\n",
       " 'sparrow',\n",
       " '!',\n",
       " 'Under',\n",
       " 'leaves',\n",
       " 'so',\n",
       " 'green',\n",
       " 'A',\n",
       " 'happy',\n",
       " 'blossom',\n",
       " 'Sees',\n",
       " 'you',\n",
       " ',',\n",
       " 'swift',\n",
       " 'as',\n",
       " 'arrow',\n",
       " ',',\n",
       " 'Seek',\n",
       " 'your',\n",
       " 'cradle',\n",
       " 'narrow',\n",
       " ',',\n",
       " 'Near',\n",
       " 'my',\n",
       " 'bosom',\n",
       " '.',\n",
       " 'Pretty',\n",
       " ',',\n",
       " 'pretty',\n",
       " 'robin',\n",
       " '!',\n",
       " 'Under',\n",
       " 'leaves',\n",
       " 'so',\n",
       " 'green',\n",
       " 'A',\n",
       " 'happy',\n",
       " 'blossom',\n",
       " 'Hears',\n",
       " 'you',\n",
       " 'sobbing',\n",
       " ',',\n",
       " 'sobbing',\n",
       " ',',\n",
       " 'Pretty',\n",
       " ',',\n",
       " 'pretty',\n",
       " 'robin',\n",
       " ',',\n",
       " 'Near',\n",
       " 'my',\n",
       " 'bosom',\n",
       " '.',\n",
       " 'THE',\n",
       " 'CHIMNEY',\n",
       " '-',\n",
       " 'SWEEPER',\n",
       " 'When',\n",
       " 'my',\n",
       " 'mother',\n",
       " 'died',\n",
       " 'I',\n",
       " 'was',\n",
       " 'very',\n",
       " 'young',\n",
       " ',',\n",
       " 'And',\n",
       " 'my',\n",
       " 'father',\n",
       " 'sold',\n",
       " 'me',\n",
       " 'while',\n",
       " 'yet',\n",
       " 'my',\n",
       " 'tongue',\n",
       " 'Could',\n",
       " 'scarcely',\n",
       " 'cry',\n",
       " '\"',\n",
       " 'Weep',\n",
       " '!',\n",
       " 'weep',\n",
       " '!',\n",
       " 'weep',\n",
       " '!',\n",
       " 'weep',\n",
       " '!\"',\n",
       " 'So',\n",
       " 'your',\n",
       " 'chimneys',\n",
       " 'I',\n",
       " 'sweep',\n",
       " ',',\n",
       " 'and',\n",
       " 'in',\n",
       " 'soot',\n",
       " 'I',\n",
       " 'sleep',\n",
       " '.',\n",
       " 'There',\n",
       " \"'\",\n",
       " 's',\n",
       " 'little',\n",
       " 'Tom',\n",
       " 'Dacre',\n",
       " ',',\n",
       " 'who',\n",
       " 'cried',\n",
       " 'when',\n",
       " 'his',\n",
       " 'head',\n",
       " ',',\n",
       " 'That',\n",
       " 'curled',\n",
       " 'like',\n",
       " 'a',\n",
       " 'lamb',\n",
       " \"'\",\n",
       " 's',\n",
       " 'back',\n",
       " ',',\n",
       " 'was',\n",
       " 'shaved',\n",
       " ';',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use for loop to get the list of all words in the blake variable.\n",
    "\n",
    "blakeList = []\n",
    "\n",
    "for word in blake:\n",
    "    blakeList.append(word)\n",
    "\n",
    "blakeList\n",
    "\n",
    "# Now you have the list of words and you can count word frequencies using the methods you learnt last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last week we learnt how to export data into a plain text file. Use the following command to export the blake variable.\n",
    "\n",
    "file = open('blake.txt', 'w')\n",
    "file.write(str(blakeList))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Last', 'night', 'I', 'had', 'a', 'dream', '.', 'I', 'want', 'to', 'tell', 'you', 'about', 'it', ',', 'but', 'I', \"'m\", 'afraid', 'you', 'wo', \"n't\", 'understand', 'it', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may use NLTK to tokenize and parse your own strings (texts) that you define here or read in from external files.\n",
    "\n",
    "myText = \"Last night I had a dream. I want to tell you about it, but I'm afraid you won't understand it.\"\n",
    "\n",
    "myTokens = nltk.word_tokenize(myText)\n",
    "\n",
    "print(myTokens)\n",
    "\n",
    "# Count all the tokens in your text with len(). Bear in mind that punctuation is also treated as tokens.\n",
    "# If you are not interested in counting punctuation signs, remove them by using replace() we used last week.\n",
    "\n",
    "len(myTokens)\n",
    "\n",
    "# Tokens are opposed to types (unique words), to use the terminology of corpus linguistics. \n",
    "# Tokens are the total number of words in a corpus.\n",
    "# 'Type' refers to the number of distinct words in a corpus. Word count helps us to identify how many distinct words are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Last night I had a dream.', \"I want to tell you about it, but I'm afraid you won't understand it.\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may break your text into sentences with sen_tokenize() so that you may count how many are there in your text.\n",
    "\n",
    "mySent = nltk.sent_tokenize(myText)\n",
    "\n",
    "print(mySent)\n",
    "\n",
    "# Count sentences with len():\n",
    "\n",
    "len(mySent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dream'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenized words and sentences are indexed. So we can slice them off by their index position.\n",
    "\n",
    "#Check a word in position 5 in myTokens:\n",
    "\n",
    "myTokens[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I want to tell you about it, but I'm afraid you won't understand it.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check a sentence in position 1 in mySent:\n",
    "\n",
    "mySent[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Last', 'JJ'),\n",
       " ('night', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('had', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('dream', 'NN'),\n",
       " ('.', '.'),\n",
       " ('I', 'PRP'),\n",
       " ('want', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('tell', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('about', 'IN'),\n",
       " ('it', 'PRP'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('I', 'PRP'),\n",
       " (\"'m\", 'VBP'),\n",
       " ('afraid', 'JJ'),\n",
       " ('you', 'PRP'),\n",
       " ('wo', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('understand', 'VB'),\n",
       " ('it', 'PRP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you may get your text tagged with pos_tag() so that you can analyze each token by their function as POS ('part-of-speech').\n",
    "\n",
    "myTags = nltk.pos_tag(myTokens)\n",
    "\n",
    "myTags\n",
    "\n",
    "# 'NN' stands for 'noun'; 'VB' is 'transitive verb', while 'VBP' is 'verb in present tense'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, you may work with the texts available on NLTK. \n",
    "\n",
    "# If you use the greedy sign * after 'import', you will get your hands on all 9 texts NLTK has to offer\n",
    "\n",
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's choose text1: Moby Dick by Herman Melville \n",
    "\n",
    "# You do not need to tokenize it by words because it's been pre-processed for us. \n",
    "\n",
    "# To count its tokens such as word and punctuation symbols, all you need is to use len(). \n",
    "\n",
    "len(text1)\n",
    "\n",
    "# It appears it has over 260k tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 1226 matches:\n",
      "s , and to teach them by what name a whale - fish is to be called in our tongue\n",
      "t which is not true .\" -- HACKLUYT \" WHALE . ... Sw . and Dan . HVAL . This ani\n",
      "ulted .\" -- WEBSTER ' S DICTIONARY \" WHALE . ... It is more immediately from th\n",
      "ISH . WAL , DUTCH . HWAL , SWEDISH . WHALE , ICELANDIC . WHALE , ENGLISH . BALE\n",
      "HWAL , SWEDISH . WHALE , ICELANDIC . WHALE , ENGLISH . BALEINE , FRENCH . BALLE\n",
      "least , take the higgledy - piggledy whale statements , however authentic , in \n",
      " dreadful gulf of this monster ' s ( whale ' s ) mouth , are immediately lost a\n",
      " patient Job .\" -- RABELAIS . \" This whale ' s liver was two cartloads .\" -- ST\n",
      " Touching that monstrous bulk of the whale or ork we have received nothing cert\n",
      " of oil will be extracted out of one whale .\" -- IBID . \" HISTORY OF LIFE AND D\n",
      "ise .\" -- KING HENRY . \" Very like a whale .\" -- HAMLET . \" Which to secure , n\n",
      "restless paine , Like as the wounded whale to shore flies thro ' the maine .\" -\n",
      ". OF SPERMA CETI AND THE SPERMA CETI WHALE . VIDE HIS V . E . \" Like Spencer ' \n",
      "t had been a sprat in the mouth of a whale .\" -- PILGRIM ' S PROGRESS . \" That \n",
      "EN ' S ANNUS MIRABILIS . \" While the whale is floating at the stern of the ship\n",
      "e ship called The Jonas - in - the - Whale . ... Some say the whale can ' t ope\n",
      " in - the - Whale . ... Some say the whale can ' t open his mouth , but that is\n",
      " masts to see whether they can see a whale , for the first discoverer has a duc\n",
      " for his pains . ... I was told of a whale taken near Shetland , that had above\n",
      "oneers told me that he caught once a whale in Spitzbergen that was white all ov\n",
      "2 , one eighty feet in length of the whale - bone kind came in , which ( as I w\n",
      "n master and kill this Sperma - ceti whale , for I could never hear of any of t\n",
      " . 1729 . \"... and the breath of the whale is frequendy attended with such an i\n",
      "ed with hoops and armed with ribs of whale .\" -- RAPE OF THE LOCK . \" If we com\n",
      "contemptible in the comparison . The whale is doubtless the largest animal in c\n"
     ]
    }
   ],
   "source": [
    "# If we are familiar with the text we are analyzing, we may look up for specific words\n",
    "\n",
    "# NLTK offers tools similar to corpus analysis. One such tool is a concordance viewer\n",
    "\n",
    "# A concordance viewer shows us every occurrence of a given word within its nearest context\n",
    "\n",
    "# Since we know that text1 is 'Moby Dick' that deals with the theme of whale hunting, look up the word 'whale'.\n",
    "\n",
    "text1.concordance('whale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship boat sea time captain world man deck pequod other whales air\n",
      "water head crew line thing side way body\n"
     ]
    }
   ],
   "source": [
    "# The concordance viewer reveals the context in which the word 'whale' occurs in the novel, e.g. 'the ___ is floating'\n",
    "# We can use NLTK method similar() to find out other words that occur in similar contexts.\n",
    "\n",
    "text1.similar('whale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the magic line and declare matplotlib (visualization module) to have plots show in Jupyter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's select some words from the similarity list generated above and plot them.\n",
    "\n",
    "text1.dispersion_plot(['whale', 'sea', 'ship', 'boat', 'water'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toils',\n",
       " 'rigging',\n",
       " 'Amittai',\n",
       " 'dreamed',\n",
       " 'sofa',\n",
       " 'overlap',\n",
       " 'bullied',\n",
       " 'broom',\n",
       " 'spiralling',\n",
       " 'spawned',\n",
       " 'lexicon',\n",
       " 'literature',\n",
       " 'foreknew',\n",
       " 'risk',\n",
       " 'blaze',\n",
       " 'enticings',\n",
       " 'wearisome',\n",
       " 'Mysteriously',\n",
       " 'Simoon',\n",
       " 'cold',\n",
       " 'census',\n",
       " 'enchanted',\n",
       " 'woods',\n",
       " 'buoy',\n",
       " 'hungry',\n",
       " 'jeopardy',\n",
       " 'Hish',\n",
       " 'angularly',\n",
       " 'incorporated',\n",
       " 'ANGLO',\n",
       " 'bleeding',\n",
       " 'walrus',\n",
       " 'syllable',\n",
       " 'Timor',\n",
       " 'shamble',\n",
       " 'undoubtedly',\n",
       " 'ribboned',\n",
       " 'operate',\n",
       " 'Nor',\n",
       " 'yelling',\n",
       " 'rules',\n",
       " 'pulverize',\n",
       " 'employ',\n",
       " 'brightest',\n",
       " 'earth',\n",
       " 'stooping',\n",
       " 'capping',\n",
       " 'interpreted',\n",
       " 'retreat',\n",
       " 'sick',\n",
       " 'adieu',\n",
       " 'dewy',\n",
       " 'hoarded',\n",
       " 'weak',\n",
       " 'killed',\n",
       " 'outlaws',\n",
       " 'Darkness',\n",
       " 'Lad',\n",
       " 'accountants',\n",
       " 'lacings',\n",
       " 'uttermost',\n",
       " 'HWAL',\n",
       " 'consorted',\n",
       " 'Kingdom',\n",
       " 'phosphorescence',\n",
       " 'smooth',\n",
       " 'More',\n",
       " 'baggage',\n",
       " 'regulating',\n",
       " 'chambers',\n",
       " 'ethereal',\n",
       " 'narrower',\n",
       " 'reflection',\n",
       " 'primal',\n",
       " 'feeders',\n",
       " 'investigation',\n",
       " 'wondrousness',\n",
       " 'anvil',\n",
       " 'foremost',\n",
       " 'funeral',\n",
       " 'greenness',\n",
       " 'iron',\n",
       " 'CRUISE',\n",
       " 'turtles',\n",
       " 'SPLICE',\n",
       " 'ringing',\n",
       " 'swelled',\n",
       " 'prize',\n",
       " '61',\n",
       " 'acuteness',\n",
       " 'maid',\n",
       " 'Silence',\n",
       " 'Patagonia',\n",
       " 'secure',\n",
       " 'probable',\n",
       " 'comparison',\n",
       " 'undiluted',\n",
       " 'peaceable',\n",
       " 'rapacious',\n",
       " 'Parliament',\n",
       " 'quitted',\n",
       " 'territorial',\n",
       " 'unaccounted',\n",
       " 'blended',\n",
       " 'ribbons',\n",
       " 'personally',\n",
       " 'accountable',\n",
       " ',--\"',\n",
       " 'INTO',\n",
       " 'dartingly',\n",
       " 'hare',\n",
       " 'affirms',\n",
       " 'libertines',\n",
       " 'intellect',\n",
       " 'profundities',\n",
       " 'jar',\n",
       " 'brazen',\n",
       " 'overcome',\n",
       " 'maintaining',\n",
       " 'mean',\n",
       " 'reconciled',\n",
       " 'withdrew',\n",
       " 'tenth',\n",
       " 'Powers',\n",
       " 'educated',\n",
       " 'encasing',\n",
       " 'heeds',\n",
       " 'hushed',\n",
       " 'HAS',\n",
       " 'Fedallah',\n",
       " ');--',\n",
       " 'admitting',\n",
       " 'poky',\n",
       " 'supplants',\n",
       " 'escape',\n",
       " 'gloomily',\n",
       " 'portions',\n",
       " 'Orion',\n",
       " 'curvetting',\n",
       " 'Reckoning',\n",
       " 'Capes',\n",
       " 'gills',\n",
       " 'villainous',\n",
       " 'Therein',\n",
       " 'intrepidity',\n",
       " 'treating',\n",
       " 'rummaged',\n",
       " 'saints',\n",
       " 'maple',\n",
       " 'precise',\n",
       " 'churchyard',\n",
       " 'slime',\n",
       " 'Roanoke',\n",
       " 'unattended',\n",
       " 'powers',\n",
       " 'tumults',\n",
       " 'enhancing',\n",
       " 'streaming',\n",
       " 'showed',\n",
       " 'renown',\n",
       " 'archipelagoes',\n",
       " 'term',\n",
       " 'Remember',\n",
       " 'sits',\n",
       " 'Saxon',\n",
       " 'foe',\n",
       " 'slices',\n",
       " 'festoon',\n",
       " 'pageant',\n",
       " 'Nicholas',\n",
       " 'whispered',\n",
       " 'falsely',\n",
       " 'sort',\n",
       " 'riveted',\n",
       " 'fairest',\n",
       " 'theirs',\n",
       " 'continue',\n",
       " 'communications',\n",
       " 'sawed',\n",
       " 'Bulkington',\n",
       " 'bet',\n",
       " 'shoved',\n",
       " 'smoker',\n",
       " 'Monsieurs',\n",
       " 'ventilated',\n",
       " 'mariners',\n",
       " 'unobtrusive',\n",
       " 'genealogies',\n",
       " 'depend',\n",
       " 'down',\n",
       " 'aware',\n",
       " 'thrilled',\n",
       " 'continual',\n",
       " 'adornment',\n",
       " 'butts',\n",
       " 'allegory',\n",
       " 'rusty',\n",
       " 'breed',\n",
       " 'scooped',\n",
       " 'maiming',\n",
       " 'research',\n",
       " 'Admiral',\n",
       " 'captain',\n",
       " 'glaring',\n",
       " 'wooden',\n",
       " 'inclining',\n",
       " 'undignified',\n",
       " '...',\n",
       " 'primitive',\n",
       " 'TAHITAN',\n",
       " 'knocks',\n",
       " 'headed',\n",
       " 'pocket',\n",
       " 'mile',\n",
       " 'disinfecting',\n",
       " 'overheard',\n",
       " 'hogshead',\n",
       " 'remorseless',\n",
       " 'dismemberer',\n",
       " 'replace',\n",
       " 'Saratoga',\n",
       " 'drunk',\n",
       " 'everybody',\n",
       " 'mutinous',\n",
       " 'colonnades',\n",
       " 'jiffy',\n",
       " 'forwards',\n",
       " 'overflowing',\n",
       " 'Potluck',\n",
       " 'slided',\n",
       " 'attempt',\n",
       " 'gentlemanlike',\n",
       " 'salvation',\n",
       " 'devout',\n",
       " 'discerned',\n",
       " 'repelled',\n",
       " 'blotting',\n",
       " 'spos',\n",
       " 'parade',\n",
       " 'symbolized',\n",
       " 'LASCAR',\n",
       " 'brides',\n",
       " 'survival',\n",
       " 'crucible',\n",
       " 'dragon',\n",
       " 'historian',\n",
       " 'Japanese',\n",
       " 'blasted',\n",
       " 'St',\n",
       " 'tempestuous',\n",
       " 'roses',\n",
       " 'Regarding',\n",
       " 'fore',\n",
       " 'vapour',\n",
       " 'imagination',\n",
       " 'Bally',\n",
       " 'surf',\n",
       " 'stiffening',\n",
       " 'lining',\n",
       " 'late',\n",
       " 'Regarded',\n",
       " 'want',\n",
       " 'clouded',\n",
       " 'surmises',\n",
       " 'unspeakably',\n",
       " 'sung',\n",
       " 'withdraw',\n",
       " 'cooled',\n",
       " 'Sam',\n",
       " 'cloud',\n",
       " 'upbubble',\n",
       " 'veiled',\n",
       " 'courteously',\n",
       " 'cautious',\n",
       " 'originate',\n",
       " 'moidores',\n",
       " 'stereotype',\n",
       " 'falls',\n",
       " 'bitterly',\n",
       " 'mistaken',\n",
       " ';--',\n",
       " 'commodores',\n",
       " 'bowing',\n",
       " 'Innocents',\n",
       " 'Never',\n",
       " 'ge',\n",
       " 'GATHER',\n",
       " 'superficial',\n",
       " 'thrusting',\n",
       " 'Egyptians',\n",
       " 'proper',\n",
       " 'gladly',\n",
       " 'unbuckling',\n",
       " 'incomplete',\n",
       " 'shouted',\n",
       " 'Canals',\n",
       " 'suffocated',\n",
       " 'hold',\n",
       " 'visitations',\n",
       " 'Other',\n",
       " 'sufficit',\n",
       " 'Authors',\n",
       " 'contemplations',\n",
       " 'crosslights',\n",
       " 'third',\n",
       " 'serve',\n",
       " 'accomplishment',\n",
       " 'dungeoned',\n",
       " 'snored',\n",
       " 'merrier',\n",
       " 'unresting',\n",
       " 'savagery',\n",
       " 'art',\n",
       " 'hieroglyphic',\n",
       " 'perspective',\n",
       " 'basketed',\n",
       " 'excite',\n",
       " 'urgent',\n",
       " 'banners',\n",
       " 'annuitants',\n",
       " 'coffee',\n",
       " 'facilitate',\n",
       " 'bonnet',\n",
       " 'Plenty',\n",
       " 'gardens',\n",
       " 'drifting',\n",
       " 'unawed',\n",
       " 'mouse',\n",
       " 'solicitously',\n",
       " 'guard',\n",
       " 'whirled',\n",
       " 'whaleboats',\n",
       " 'MULTUM',\n",
       " 'Pitchpoling',\n",
       " 'pulpits',\n",
       " 'charms',\n",
       " 'slackened',\n",
       " 'helping',\n",
       " 'undecreasing',\n",
       " 'watchmakers',\n",
       " 'lashes',\n",
       " 'brawlers',\n",
       " 'dropped',\n",
       " 'abasement',\n",
       " 'dowers',\n",
       " 'effectual',\n",
       " 'enjoined',\n",
       " 'VERSION',\n",
       " 'pier',\n",
       " 'stander',\n",
       " 'luckily',\n",
       " 'Dons',\n",
       " 'nails',\n",
       " 'crape',\n",
       " 'mainly',\n",
       " 'indications',\n",
       " 'er',\n",
       " 'tombstones',\n",
       " 'piloted',\n",
       " 'removing',\n",
       " 'Nat',\n",
       " 'Dominic',\n",
       " 'VESSEL',\n",
       " 'stores',\n",
       " 'arose',\n",
       " 'incarnated',\n",
       " 'supply',\n",
       " 'parcel',\n",
       " 'moored',\n",
       " 'Top',\n",
       " 'evolutions',\n",
       " 'sauntering',\n",
       " 'Unconsciously',\n",
       " 'cleat',\n",
       " 'particularly',\n",
       " 'prophecy',\n",
       " 'ruggedest',\n",
       " 'holding',\n",
       " 'cruise',\n",
       " 'extinguishing',\n",
       " 'colder',\n",
       " 'tableau',\n",
       " 'shoals',\n",
       " 'hump',\n",
       " 'frigid',\n",
       " 'equity',\n",
       " 'apothecary',\n",
       " 'palpably',\n",
       " 'Icelandic',\n",
       " 'beaching',\n",
       " 'YE',\n",
       " 'strained',\n",
       " 'scorn',\n",
       " 'gateway',\n",
       " 'COLNETT',\n",
       " 'torrid',\n",
       " 'grooved',\n",
       " 'fixedly',\n",
       " 'merging',\n",
       " 'savannas',\n",
       " 'BREACH',\n",
       " 'protection',\n",
       " 'questionings',\n",
       " 'RESPECTABLE',\n",
       " 'scout',\n",
       " 'creak',\n",
       " 'chapter',\n",
       " 'degrees',\n",
       " 'quiescent',\n",
       " 'provides',\n",
       " 'magnanimity',\n",
       " 'asses',\n",
       " 'hourly',\n",
       " 'busy',\n",
       " 'hares',\n",
       " 'jingle',\n",
       " 'neighbor',\n",
       " 'speaking',\n",
       " 'resolving',\n",
       " 'reef',\n",
       " 'sockets',\n",
       " 'suckled',\n",
       " 'feeling',\n",
       " 'cove',\n",
       " 'flume',\n",
       " 'ideas',\n",
       " 'STRAPS',\n",
       " 'pricking',\n",
       " 'tranced',\n",
       " '(',\n",
       " 'strands',\n",
       " 'heartless',\n",
       " 'sheepishly',\n",
       " 'Bear',\n",
       " 'macassar',\n",
       " 'easier',\n",
       " 'Set',\n",
       " 'literal',\n",
       " 'arts',\n",
       " 'splits',\n",
       " 'bore',\n",
       " 'vital',\n",
       " '49',\n",
       " 'ANY',\n",
       " 'Pedestrians',\n",
       " 'exhaling',\n",
       " '25',\n",
       " 'fierce',\n",
       " 'Gilder',\n",
       " 'tropical',\n",
       " 'streams',\n",
       " 'capsizings',\n",
       " 'spire',\n",
       " 'brace',\n",
       " 'satisfactorily',\n",
       " 'heavens',\n",
       " 'bit',\n",
       " 'ETCHINGS',\n",
       " 'violate',\n",
       " 'heated',\n",
       " 'precisely',\n",
       " 'midday',\n",
       " 'Dead',\n",
       " 'Quohog',\n",
       " 'Watch',\n",
       " 'MSS',\n",
       " 'fishermen',\n",
       " 'muttering',\n",
       " 'mateship',\n",
       " 'alluringly',\n",
       " 'mermaids',\n",
       " 'stretched',\n",
       " 'Often',\n",
       " 'river',\n",
       " 'Fasting',\n",
       " 'cash',\n",
       " 'utilities',\n",
       " 'frost',\n",
       " 'gesticulated',\n",
       " 'device',\n",
       " 'lucifers',\n",
       " 'grapple',\n",
       " 'injury',\n",
       " 'undertaken',\n",
       " 'Napoleon',\n",
       " 'storied',\n",
       " 'recorded',\n",
       " 'statement',\n",
       " 'bridegrooms',\n",
       " 'ultimate',\n",
       " 'Evil',\n",
       " 'inferior',\n",
       " 'independent',\n",
       " 'coverlid',\n",
       " 'Witness',\n",
       " 'cringed',\n",
       " 'far',\n",
       " 'troubled',\n",
       " 'visitation',\n",
       " 'Merely',\n",
       " 'meadow',\n",
       " 'netted',\n",
       " 'mammiferous',\n",
       " 'druggs',\n",
       " 'insensible',\n",
       " 'context',\n",
       " 'Wet',\n",
       " 'urging',\n",
       " 'comply',\n",
       " 'demonism',\n",
       " 'magniloquent',\n",
       " 'Easy',\n",
       " 'Marine',\n",
       " 'pronounced',\n",
       " 'YORK',\n",
       " 'notes',\n",
       " 'camphorated',\n",
       " 'ninety',\n",
       " 'fiddler',\n",
       " '97',\n",
       " 'fragments',\n",
       " 'supernaturalness',\n",
       " 'dejected',\n",
       " 'outworks',\n",
       " 'STRAFFORD',\n",
       " 'eloped',\n",
       " 'Afterwards',\n",
       " 'tissued',\n",
       " 'ATTACKED',\n",
       " 'wall',\n",
       " 'uninvitedly',\n",
       " 'controllable',\n",
       " 'symptom',\n",
       " 'attribute',\n",
       " 'unappalled',\n",
       " 'sounded',\n",
       " 'Watching',\n",
       " 'tin',\n",
       " 'replenish',\n",
       " 'mumbling',\n",
       " 'gulp',\n",
       " 'defection',\n",
       " 'companied',\n",
       " 'allusion',\n",
       " 'sleet',\n",
       " 'hugged',\n",
       " 'abortion',\n",
       " 'localness',\n",
       " '--\\'\"',\n",
       " 'Persians',\n",
       " 'infected',\n",
       " 'chosen',\n",
       " 'Pope',\n",
       " 'menacing',\n",
       " 'monstrousest',\n",
       " 'manes',\n",
       " 'buckler',\n",
       " 'threading',\n",
       " 'Dost',\n",
       " 'Squaring',\n",
       " 'sickle',\n",
       " 'nill',\n",
       " 'swears',\n",
       " 'real',\n",
       " 'positive',\n",
       " 'SAILORS',\n",
       " 'firmly',\n",
       " 'traceable',\n",
       " 'mills',\n",
       " 'Gamming',\n",
       " 'wearied',\n",
       " 'since',\n",
       " 'doom',\n",
       " 'Pity',\n",
       " 'sailors',\n",
       " 'healthful',\n",
       " 'kine',\n",
       " 'Duck',\n",
       " 'day',\n",
       " 'christenings',\n",
       " 'pangs',\n",
       " 'Immediately',\n",
       " 'Trumpet',\n",
       " 'tier',\n",
       " 'combing',\n",
       " 'weave',\n",
       " 'plying',\n",
       " 'grandeur',\n",
       " 'heightens',\n",
       " 'atom',\n",
       " 'eddyings',\n",
       " 'triumphs',\n",
       " 'whalemen',\n",
       " 'noise',\n",
       " 'prodigious',\n",
       " 'activity',\n",
       " 'felonious',\n",
       " 'irresolute',\n",
       " 'rafts',\n",
       " 'wheezing',\n",
       " 'artificially',\n",
       " 'chapels',\n",
       " 'SPITZBERGEN',\n",
       " 'Be',\n",
       " 'Scragg',\n",
       " 'divides',\n",
       " 'fatalistic',\n",
       " 'lipped',\n",
       " 'combed',\n",
       " 'glorified',\n",
       " 'plucked',\n",
       " 'impressions',\n",
       " 'hurled',\n",
       " 'steps',\n",
       " ':--\"',\n",
       " 'DEVIL',\n",
       " 'angry',\n",
       " 'walls',\n",
       " 'Ding',\n",
       " 'recruit',\n",
       " 'pick',\n",
       " 'phantom',\n",
       " 'pot',\n",
       " 'sharpening',\n",
       " 'curly',\n",
       " 'aid',\n",
       " 'ebon',\n",
       " 'Bulwarks',\n",
       " 'confidently',\n",
       " 'Have',\n",
       " 'lies',\n",
       " 'dissect',\n",
       " 'hilarity',\n",
       " 'sticks',\n",
       " 'marks',\n",
       " 'urn',\n",
       " 'swart',\n",
       " 'Eight',\n",
       " 'toiled',\n",
       " 'wad',\n",
       " 'momentary',\n",
       " 'barnacle',\n",
       " 'skrimmage',\n",
       " 'worm',\n",
       " 'please',\n",
       " 'Indolence',\n",
       " 'run',\n",
       " 'subjected',\n",
       " 'generally',\n",
       " 'grand',\n",
       " 'sharp',\n",
       " 'legislative',\n",
       " 'scheme',\n",
       " 'suit',\n",
       " 'as',\n",
       " 'surround',\n",
       " 'Macey',\n",
       " 'dragged',\n",
       " 'dumb',\n",
       " 'Fife',\n",
       " 'Cannibal',\n",
       " 'corporal',\n",
       " 'Canst',\n",
       " 'citron',\n",
       " 'slavery',\n",
       " 'lighted',\n",
       " 'cork',\n",
       " 'XVI',\n",
       " 'wrought',\n",
       " 'fright',\n",
       " 'steadying',\n",
       " 'Cant',\n",
       " 'assure',\n",
       " 'Constantinople',\n",
       " 'devotees',\n",
       " 'visitants',\n",
       " 'disclosures',\n",
       " 'tiled',\n",
       " 'coral',\n",
       " 'uncheered',\n",
       " 'mishap',\n",
       " 'candid',\n",
       " 'reverie',\n",
       " 'origin',\n",
       " 'unassailable',\n",
       " 'alas',\n",
       " 'lengthened',\n",
       " 'lid',\n",
       " 'rascally',\n",
       " 'Evangelist',\n",
       " 'repute',\n",
       " 'narrations',\n",
       " 'elongated',\n",
       " 'looking',\n",
       " 'look',\n",
       " 'overrun',\n",
       " 'staggering',\n",
       " 'granite',\n",
       " 'stilly',\n",
       " 'appeared',\n",
       " 'oder',\n",
       " 'plumage',\n",
       " 'Greenlanders',\n",
       " 'mittened',\n",
       " 'Typhoon',\n",
       " 'corridors',\n",
       " 'unforgiven',\n",
       " 'tutelary',\n",
       " 'vine',\n",
       " 'Ahab',\n",
       " 'pea',\n",
       " 'deer',\n",
       " 'curses',\n",
       " 'cabled',\n",
       " 'commons',\n",
       " 'nosed',\n",
       " 'grandiloquent',\n",
       " 'bites',\n",
       " 'glass',\n",
       " 'appeal',\n",
       " 'adopt',\n",
       " 'leaf',\n",
       " 'arch',\n",
       " 'wandered',\n",
       " 'perceptible',\n",
       " 'reg',\n",
       " 'constant',\n",
       " 'save',\n",
       " 'screamed',\n",
       " 'poise',\n",
       " 'Whitsuntide',\n",
       " 'Virgin',\n",
       " 'fathomless',\n",
       " 'affluent',\n",
       " 'progress',\n",
       " 'form',\n",
       " 'horizontal',\n",
       " 'stomachs',\n",
       " 'firmer',\n",
       " 'There',\n",
       " 'vindictiveness',\n",
       " 'limitless',\n",
       " 'dispensed',\n",
       " 'arterial',\n",
       " 'enemies',\n",
       " 'Too',\n",
       " 'outblown',\n",
       " 'historic',\n",
       " 'askance',\n",
       " 'commanding',\n",
       " 'treasures',\n",
       " 'machine',\n",
       " 'water',\n",
       " 'judgments',\n",
       " 'suppose',\n",
       " 'cassock',\n",
       " 'flowing',\n",
       " 'SPOUTING',\n",
       " 'canals',\n",
       " 'tiara',\n",
       " 'sport',\n",
       " 'maddens',\n",
       " 'sewing',\n",
       " 'spears',\n",
       " 'fine',\n",
       " 'Green',\n",
       " 'extravaganzas',\n",
       " 'leaner',\n",
       " 'confinement',\n",
       " 'endwise',\n",
       " 'perverse',\n",
       " 'shirts',\n",
       " 'success',\n",
       " 'tunic',\n",
       " 'laughing',\n",
       " 'Miguel',\n",
       " 'Grenadier',\n",
       " 'akin',\n",
       " 'concernments',\n",
       " 'devoting',\n",
       " 'inland',\n",
       " 'changing',\n",
       " 'scruples',\n",
       " 'Deity',\n",
       " 'highest',\n",
       " 'fathom',\n",
       " 'heedfulness',\n",
       " 'genius',\n",
       " 'wickedness',\n",
       " 'duck',\n",
       " 'jeopardized',\n",
       " 'ape',\n",
       " 'keep',\n",
       " 'visions',\n",
       " 'plaguey',\n",
       " 'majestically',\n",
       " 'sinew',\n",
       " 'biggest',\n",
       " 'bustle',\n",
       " 'privations',\n",
       " 'Way',\n",
       " 'ISOLATO',\n",
       " 'WILLIS',\n",
       " 'however',\n",
       " 'writers',\n",
       " 'poet',\n",
       " 'seaward',\n",
       " 'mirror',\n",
       " 'lifting',\n",
       " 'princess',\n",
       " 'teak',\n",
       " '$',\n",
       " 'vacuum',\n",
       " 'afar',\n",
       " 'Fired',\n",
       " 'miser',\n",
       " 'scrolled',\n",
       " 'style',\n",
       " 'expressions',\n",
       " 'recovery',\n",
       " 'sailings',\n",
       " 'Fernandes',\n",
       " 'understood',\n",
       " 'relent',\n",
       " 'NEST',\n",
       " 'patted',\n",
       " 'Manilla',\n",
       " 'lanterns',\n",
       " 'thirteen',\n",
       " 'gripping',\n",
       " 'stop',\n",
       " 'foaled',\n",
       " 'cheer',\n",
       " 'completing',\n",
       " 'rank',\n",
       " 'paced',\n",
       " 'advised',\n",
       " 'swiftest',\n",
       " 'aforesaid',\n",
       " 'Jonah',\n",
       " 'forges',\n",
       " 'Stepping',\n",
       " 'Plowdon',\n",
       " 'seeking',\n",
       " 'unexhausted',\n",
       " 'artisan',\n",
       " 'alone',\n",
       " 'shades',\n",
       " 'known',\n",
       " 'grinning',\n",
       " 'knights',\n",
       " 'jeweller',\n",
       " '400',\n",
       " 'handle',\n",
       " 'suckingly',\n",
       " 'vehemently',\n",
       " 'quite',\n",
       " 'six',\n",
       " 'lady',\n",
       " 'emphasis',\n",
       " 'TRIUMPH',\n",
       " 'dyspepsias',\n",
       " 'referring',\n",
       " 'pell',\n",
       " 'Fine',\n",
       " 'tastefully',\n",
       " 'Cyclades',\n",
       " 'Omen',\n",
       " 'signal',\n",
       " '*',\n",
       " 'gone',\n",
       " 'indulging',\n",
       " 'animate',\n",
       " 'Albino',\n",
       " 'dangerous',\n",
       " 'page',\n",
       " 'grooves',\n",
       " 'jingling',\n",
       " 'buoys',\n",
       " 'squire',\n",
       " 'sufficiently',\n",
       " 'undressed',\n",
       " 'hey',\n",
       " 'speaks',\n",
       " 'stepped',\n",
       " 'needful',\n",
       " 'responses',\n",
       " 'unsay',\n",
       " 'honed',\n",
       " 'Story',\n",
       " 'Categut',\n",
       " 'puffing',\n",
       " 'medicine',\n",
       " 'High',\n",
       " 'listener',\n",
       " 'complacent',\n",
       " 'tornadoes',\n",
       " 'illuminating',\n",
       " 'bluer',\n",
       " 'guests',\n",
       " 'transcendent',\n",
       " 'opportunity',\n",
       " 'motto',\n",
       " 'wonderfully',\n",
       " 'cricket',\n",
       " 'hermaphroditical',\n",
       " 'buckets',\n",
       " 'doxology',\n",
       " 'Hindoos',\n",
       " 'ROLL',\n",
       " 'launchest',\n",
       " 'comparative',\n",
       " 'Thy',\n",
       " 'Suspended',\n",
       " 'likely',\n",
       " 'great',\n",
       " 'gifted',\n",
       " 'Physiognomy',\n",
       " 'rabble',\n",
       " 'wholly',\n",
       " 'slower',\n",
       " 'How',\n",
       " 'Hurrah',\n",
       " 'basis',\n",
       " 'HANDS',\n",
       " 'slay',\n",
       " 'Daboll',\n",
       " 'painstaking',\n",
       " 'wounds',\n",
       " 'clings',\n",
       " 'unsmoothable',\n",
       " 'PILGRIM',\n",
       " 'obscured',\n",
       " 'treacheries',\n",
       " 'ferocious',\n",
       " 'withhold',\n",
       " 'barbarians',\n",
       " 'highwaymen',\n",
       " 'lungs',\n",
       " 'clutching',\n",
       " 'fashioned',\n",
       " 'hereditarily',\n",
       " 'characteristics',\n",
       " 'procured',\n",
       " 'wildly',\n",
       " 'estimate',\n",
       " 'perusal',\n",
       " 'gout',\n",
       " 'freshets',\n",
       " 'propriety',\n",
       " 'Prince',\n",
       " 'standpoint',\n",
       " 'wonderfulness',\n",
       " 'poked',\n",
       " 'tramping',\n",
       " 'pedigree',\n",
       " 'minute',\n",
       " 'knitted',\n",
       " 'trending',\n",
       " 'usual',\n",
       " 'Cadiz',\n",
       " 'direst',\n",
       " 'astern',\n",
       " 'whistlingly',\n",
       " 'Scorpio',\n",
       " 'physiognomically',\n",
       " 'yon',\n",
       " 'pertained',\n",
       " 'surges',\n",
       " 'evilly',\n",
       " 'exhibition',\n",
       " 'affinities',\n",
       " 'sperm',\n",
       " 'tugged',\n",
       " 'mastery',\n",
       " 'streets',\n",
       " 'GATHERED',\n",
       " 'persuade',\n",
       " 'confabulations',\n",
       " 'COMMODORE',\n",
       " 'shudder',\n",
       " 'Draws',\n",
       " '28',\n",
       " ':',\n",
       " 'sawn',\n",
       " 'breezes',\n",
       " 'names',\n",
       " 'clumsily',\n",
       " 'seasoned',\n",
       " 'catalogue',\n",
       " 'cleansing',\n",
       " 'reddenest',\n",
       " 'quiver',\n",
       " 'shoots',\n",
       " 'agony',\n",
       " 'improbable',\n",
       " 'Put',\n",
       " 'three',\n",
       " 'pedestal',\n",
       " 'boast',\n",
       " ...}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's explore the vocabulary of Moby Dick in more quantitative ways\n",
    "# We have already found out with len(text1) that it contains over 260k tokens. \n",
    "# But many words repeat across the text as, for example, the concordancer revealed 'whale' seems to appear 25 times\n",
    "# To view and count only the word items rather than word tokens, we need to use set().\n",
    "\n",
    "set(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19317"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the list above, 'whale' will appear only once. Yet its plural form 'whales' will be counted as a separate word item\n",
    "# In the corpus literature, unique words are called 'types', while their multiple occurrences are called tokens\n",
    "# Let's count how many unique words and symbols the novel contain now\n",
    "\n",
    "len(set(text1))\n",
    "\n",
    "# The count drops to 19k types against 260k tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Blackberrying\n",
      "By Sylvia Plath\n",
      "Nobody in the lane, and nothing, nothing but blackberries,   \n",
      "Blackberries on either side, though on the right mainly,\n",
      "A blackberry alley, going down in hooks, and a sea\n",
      "Somewhere at the end of it, heaving. Blackberries\n",
      "Big as the ball of my thumb, and dumb as eyes\n",
      "Ebon in the hedges, fat\n",
      "With blue-red juices. These they squander on my fingers.\n",
      "I had not asked for such a blood sisterhood; they must love me.\n",
      "They accommodate themselves to my milkbottle, flattening their sides.\n",
      "\n",
      "Overhead go the choughs in black, cacophonous flocks—\n",
      "Bits of burnt paper wheeling in a blown sky.\n",
      "Theirs is the only voice, protesting, protesting.\n",
      "I do not think the sea will appear at all.\n",
      "The high, green meadows are glowing, as if lit from within.\n",
      "I come to one bush of berries so ripe it is a bush of flies,\n",
      "Hanging their bluegreen bellies and their wing panes in a Chinese screen.\n",
      "The honey-feast of the berries has stunned them; they believe in heaven.   \n",
      "One more hook, and the berries and bushes end.\n",
      "\n",
      "The only thing to come now is the sea.\n",
      "From between two hills a sudden wind funnels at me,   \n",
      "Slapping its phantom laundry in my face.\n",
      "These hills are too green and sweet to have tasted salt.\n",
      "I follow the sheep path between them. A last hook brings me   \n",
      "To the hills’ northern face, and the face is orange rock   \n",
      "That looks out on nothing, nothing but a great space   \n",
      "Of white and pewter lights, and a din like silversmiths   \n",
      "Beating and beating at an intractable metal.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We learnt how to read in a txt file last week.\n",
    "\n",
    "poem = open('Blackberrying.txt', 'r')\n",
    "\n",
    "\n",
    "BlackBerry = poem.read()\n",
    "\n",
    "print(BlackBerry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "blackberrying\n",
      "by sylvia plath\n",
      "nobody in the lane, and nothing, nothing but blackberries,   \n",
      "blackberries on either side, though on the right mainly,\n",
      "a blackberry alley, going down in hooks, and a sea\n",
      "somewhere at the end of it, heaving. blackberries\n",
      "big as the ball of my thumb, and dumb as eyes\n",
      "ebon in the hedges, fat\n",
      "with blue-red juices. these they squander on my fingers.\n",
      "i had not asked for such a blood sisterhood; they must love me.\n",
      "they accommodate themselves to my milkbottle, flattening their sides.\n",
      "\n",
      "overhead go the choughs in black, cacophonous flocks—\n",
      "bits of burnt paper wheeling in a blown sky.\n",
      "theirs is the only voice, protesting, protesting.\n",
      "i do not think the sea will appear at all.\n",
      "the high, green meadows are glowing, as if lit from within.\n",
      "i come to one bush of berries so ripe it is a bush of flies,\n",
      "hanging their bluegreen bellies and their wing panes in a chinese screen.\n",
      "the honey-feast of the berries has stunned them; they believe in heaven.   \n",
      "one more hook, and the berries and bushes end.\n",
      "\n",
      "the only thing to come now is the sea.\n",
      "from between two hills a sudden wind funnels at me,   \n",
      "slapping its phantom laundry in my face.\n",
      "these hills are too green and sweet to have tasted salt.\n",
      "i follow the sheep path between them. a last hook brings me   \n",
      "to the hills’ northern face, and the face is orange rock   \n",
      "that looks out on nothing, nothing but a great space   \n",
      "of white and pewter lights, and a din like silversmiths   \n",
      "beating and beating at an intractable metal.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's turn all the text to lower cases:\n",
    "\n",
    "poem_lower = BlackBerry.lower()\n",
    "\n",
    "print(poem_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The list of the most frequent stopwords is predefined in the nltk module\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('english')\n",
    "\n",
    "# There are other stopword lists for other languages in nltk, e.g. Russian, Chinese etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's store the nltk stopwords in the variable stop against which we'll match the words in our variable 'poem_lower'.\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blackberrying', 'by', 'sylvia', 'plath', 'nobody', 'in', 'the', 'lane', ',', 'and', 'nothing', ',', 'nothing', 'but', 'blackberries', ',', 'blackberries', 'on', 'either', 'side', ',', 'though', 'on', 'the', 'right', 'mainly', ',', 'a', 'blackberry', 'alley', ',', 'going', 'down', 'in', 'hooks', ',', 'and', 'a', 'sea', 'somewhere', 'at', 'the', 'end', 'of', 'it', ',', 'heaving', '.', 'blackberries', 'big', 'as', 'the', 'ball', 'of', 'my', 'thumb', ',', 'and', 'dumb', 'as', 'eyes', 'ebon', 'in', 'the', 'hedges', ',', 'fat', 'with', 'blue-red', 'juices', '.', 'these', 'they', 'squander', 'on', 'my', 'fingers', '.', 'i', 'had', 'not', 'asked', 'for', 'such', 'a', 'blood', 'sisterhood', ';', 'they', 'must', 'love', 'me', '.', 'they', 'accommodate', 'themselves', 'to', 'my', 'milkbottle', ',', 'flattening', 'their', 'sides', '.', 'overhead', 'go', 'the', 'choughs', 'in', 'black', ',', 'cacophonous', 'flocks—', 'bits', 'of', 'burnt', 'paper', 'wheeling', 'in', 'a', 'blown', 'sky', '.', 'theirs', 'is', 'the', 'only', 'voice', ',', 'protesting', ',', 'protesting', '.', 'i', 'do', 'not', 'think', 'the', 'sea', 'will', 'appear', 'at', 'all', '.', 'the', 'high', ',', 'green', 'meadows', 'are', 'glowing', ',', 'as', 'if', 'lit', 'from', 'within', '.', 'i', 'come', 'to', 'one', 'bush', 'of', 'berries', 'so', 'ripe', 'it', 'is', 'a', 'bush', 'of', 'flies', ',', 'hanging', 'their', 'bluegreen', 'bellies', 'and', 'their', 'wing', 'panes', 'in', 'a', 'chinese', 'screen', '.', 'the', 'honey-feast', 'of', 'the', 'berries', 'has', 'stunned', 'them', ';', 'they', 'believe', 'in', 'heaven', '.', 'one', 'more', 'hook', ',', 'and', 'the', 'berries', 'and', 'bushes', 'end', '.', 'the', 'only', 'thing', 'to', 'come', 'now', 'is', 'the', 'sea', '.', 'from', 'between', 'two', 'hills', 'a', 'sudden', 'wind', 'funnels', 'at', 'me', ',', 'slapping', 'its', 'phantom', 'laundry', 'in', 'my', 'face', '.', 'these', 'hills', 'are', 'too', 'green', 'and', 'sweet', 'to', 'have', 'tasted', 'salt', '.', 'i', 'follow', 'the', 'sheep', 'path', 'between', 'them', '.', 'a', 'last', 'hook', 'brings', 'me', 'to', 'the', 'hills', '’', 'northern', 'face', ',', 'and', 'the', 'face', 'is', 'orange', 'rock', 'that', 'looks', 'out', 'on', 'nothing', ',', 'nothing', 'but', 'a', 'great', 'space', 'of', 'white', 'and', 'pewter', 'lights', ',', 'and', 'a', 'din', 'like', 'silversmiths', 'beating', 'and', 'beating', 'at', 'an', 'intractable', 'metal', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the words of our poem_lower - that is, break the text into words.\n",
    "\n",
    "tokPoem = nltk.word_tokenize(poem_lower)\n",
    "\n",
    "print(tokPoem)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blackberrying': 1, 'by': 1, 'sylvia': 1, 'plath': 1, 'nobody': 1, 'in': 8, 'the': 17, 'lane': 1, ',': 22, 'and': 11, 'nothing': 4, 'but': 2, 'blackberries': 3, 'on': 4, 'either': 1, 'side': 1, 'though': 1, 'right': 1, 'mainly': 1, 'a': 10, 'blackberry': 1, 'alley': 1, 'going': 1, 'down': 1, 'hooks': 1, 'sea': 3, 'somewhere': 1, 'at': 4, 'end': 2, 'of': 7, 'it': 2, 'heaving': 1, '.': 17, 'big': 1, 'as': 3, 'ball': 1, 'my': 4, 'thumb': 1, 'dumb': 1, 'eyes': 1, 'ebon': 1, 'hedges': 1, 'fat': 1, 'with': 1, 'blue-red': 1, 'juices': 1, 'these': 2, 'they': 4, 'squander': 1, 'fingers': 1, 'i': 4, 'had': 1, 'not': 2, 'asked': 1, 'for': 1, 'such': 1, 'blood': 1, 'sisterhood': 1, ';': 2, 'must': 1, 'love': 1, 'me': 3, 'accommodate': 1, 'themselves': 1, 'to': 5, 'milkbottle': 1, 'flattening': 1, 'their': 3, 'sides': 1, 'overhead': 1, 'go': 1, 'choughs': 1, 'black': 1, 'cacophonous': 1, 'flocks—': 1, 'bits': 1, 'burnt': 1, 'paper': 1, 'wheeling': 1, 'blown': 1, 'sky': 1, 'theirs': 1, 'is': 4, 'only': 2, 'voice': 1, 'protesting': 2, 'do': 1, 'think': 1, 'will': 1, 'appear': 1, 'all': 1, 'high': 1, 'green': 2, 'meadows': 1, 'are': 2, 'glowing': 1, 'if': 1, 'lit': 1, 'from': 2, 'within': 1, 'come': 2, 'one': 2, 'bush': 2, 'berries': 3, 'so': 1, 'ripe': 1, 'flies': 1, 'hanging': 1, 'bluegreen': 1, 'bellies': 1, 'wing': 1, 'panes': 1, 'chinese': 1, 'screen': 1, 'honey-feast': 1, 'has': 1, 'stunned': 1, 'them': 2, 'believe': 1, 'heaven': 1, 'more': 1, 'hook': 2, 'bushes': 1, 'thing': 1, 'now': 1, 'between': 2, 'two': 1, 'hills': 3, 'sudden': 1, 'wind': 1, 'funnels': 1, 'slapping': 1, 'its': 1, 'phantom': 1, 'laundry': 1, 'face': 3, 'too': 1, 'sweet': 1, 'have': 1, 'tasted': 1, 'salt': 1, 'follow': 1, 'sheep': 1, 'path': 1, 'last': 1, 'brings': 1, '’': 1, 'northern': 1, 'orange': 1, 'rock': 1, 'that': 1, 'looks': 1, 'out': 1, 'great': 1, 'space': 1, 'white': 1, 'pewter': 1, 'lights': 1, 'din': 1, 'like': 1, 'silversmiths': 1, 'beating': 2, 'an': 1, 'intractable': 1, 'metal': 1}\n"
     ]
    }
   ],
   "source": [
    "# Let's use one of three methods of counting word frequencies that we learnt last week.\n",
    "\n",
    "\n",
    "Freq = {}\n",
    "\n",
    "for word in tokPoem:\n",
    "    Freq[word] = tokPoem.count(word)\n",
    "\n",
    "print(Freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blackberrying',\n",
       " 'sylvia',\n",
       " 'plath',\n",
       " 'nobody',\n",
       " 'lane',\n",
       " ',',\n",
       " 'nothing',\n",
       " ',',\n",
       " 'nothing',\n",
       " 'blackberries',\n",
       " ',',\n",
       " 'blackberries',\n",
       " 'either',\n",
       " 'side',\n",
       " ',',\n",
       " 'though',\n",
       " 'right',\n",
       " 'mainly',\n",
       " ',',\n",
       " 'blackberry',\n",
       " 'alley',\n",
       " ',',\n",
       " 'going',\n",
       " 'hooks',\n",
       " ',',\n",
       " 'sea',\n",
       " 'somewhere',\n",
       " 'end',\n",
       " ',',\n",
       " 'heaving',\n",
       " '.',\n",
       " 'blackberries',\n",
       " 'big',\n",
       " 'ball',\n",
       " 'thumb',\n",
       " ',',\n",
       " 'dumb',\n",
       " 'eyes',\n",
       " 'ebon',\n",
       " 'hedges',\n",
       " ',',\n",
       " 'fat',\n",
       " 'blue-red',\n",
       " 'juices',\n",
       " '.',\n",
       " 'squander',\n",
       " 'fingers',\n",
       " '.',\n",
       " 'asked',\n",
       " 'blood',\n",
       " 'sisterhood',\n",
       " ';',\n",
       " 'must',\n",
       " 'love',\n",
       " '.',\n",
       " 'accommodate',\n",
       " 'milkbottle',\n",
       " ',',\n",
       " 'flattening',\n",
       " 'sides',\n",
       " '.',\n",
       " 'overhead',\n",
       " 'go',\n",
       " 'choughs',\n",
       " 'black',\n",
       " ',',\n",
       " 'cacophonous',\n",
       " 'flocks—',\n",
       " 'bits',\n",
       " 'burnt',\n",
       " 'paper',\n",
       " 'wheeling',\n",
       " 'blown',\n",
       " 'sky',\n",
       " '.',\n",
       " 'voice',\n",
       " ',',\n",
       " 'protesting',\n",
       " ',',\n",
       " 'protesting',\n",
       " '.',\n",
       " 'think',\n",
       " 'sea',\n",
       " 'appear',\n",
       " '.',\n",
       " 'high',\n",
       " ',',\n",
       " 'green',\n",
       " 'meadows',\n",
       " 'glowing',\n",
       " ',',\n",
       " 'lit',\n",
       " 'within',\n",
       " '.',\n",
       " 'come',\n",
       " 'one',\n",
       " 'bush',\n",
       " 'berries',\n",
       " 'ripe',\n",
       " 'bush',\n",
       " 'flies',\n",
       " ',',\n",
       " 'hanging',\n",
       " 'bluegreen',\n",
       " 'bellies',\n",
       " 'wing',\n",
       " 'panes',\n",
       " 'chinese',\n",
       " 'screen',\n",
       " '.',\n",
       " 'honey-feast',\n",
       " 'berries',\n",
       " 'stunned',\n",
       " ';',\n",
       " 'believe',\n",
       " 'heaven',\n",
       " '.',\n",
       " 'one',\n",
       " 'hook',\n",
       " ',',\n",
       " 'berries',\n",
       " 'bushes',\n",
       " 'end',\n",
       " '.',\n",
       " 'thing',\n",
       " 'come',\n",
       " 'sea',\n",
       " '.',\n",
       " 'two',\n",
       " 'hills',\n",
       " 'sudden',\n",
       " 'wind',\n",
       " 'funnels',\n",
       " ',',\n",
       " 'slapping',\n",
       " 'phantom',\n",
       " 'laundry',\n",
       " 'face',\n",
       " '.',\n",
       " 'hills',\n",
       " 'green',\n",
       " 'sweet',\n",
       " 'tasted',\n",
       " 'salt',\n",
       " '.',\n",
       " 'follow',\n",
       " 'sheep',\n",
       " 'path',\n",
       " '.',\n",
       " 'last',\n",
       " 'hook',\n",
       " 'brings',\n",
       " 'hills',\n",
       " '’',\n",
       " 'northern',\n",
       " 'face',\n",
       " ',',\n",
       " 'face',\n",
       " 'orange',\n",
       " 'rock',\n",
       " 'looks',\n",
       " 'nothing',\n",
       " ',',\n",
       " 'nothing',\n",
       " 'great',\n",
       " 'space',\n",
       " 'white',\n",
       " 'pewter',\n",
       " 'lights',\n",
       " ',',\n",
       " 'din',\n",
       " 'like',\n",
       " 'silversmiths',\n",
       " 'beating',\n",
       " 'beating',\n",
       " 'intractable',\n",
       " 'metal',\n",
       " '.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get rid of stopwords by using the variable stop \n",
    "\n",
    "cleanPoem = [w for w in tokPoem if w not in stop]\n",
    "\n",
    "cleanPoem\n",
    "\n",
    "# In result, you will get a list of strings (words) without those most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'blackberrying': 1, 'sylvia': 1, 'plath': 1, 'nobody': 1, 'lane': 1, ',': 22, 'nothing': 4, 'blackberries': 3, 'either': 1, 'side': 1, 'though': 1, 'right': 1, 'mainly': 1, 'blackberry': 1, 'alley': 1, 'going': 1, 'hooks': 1, 'sea': 3, 'somewhere': 1, 'end': 2, 'heaving': 1, '.': 17, 'big': 1, 'ball': 1, 'thumb': 1, 'dumb': 1, 'eyes': 1, 'ebon': 1, 'hedges': 1, 'fat': 1, 'blue-red': 1, 'juices': 1, 'squander': 1, 'fingers': 1, 'asked': 1, 'blood': 1, 'sisterhood': 1, ';': 2, 'must': 1, 'love': 1, 'accommodate': 1, 'milkbottle': 1, 'flattening': 1, 'sides': 1, 'overhead': 1, 'go': 1, 'choughs': 1, 'black': 1, 'cacophonous': 1, 'flocks—': 1, 'bits': 1, 'burnt': 1, 'paper': 1, 'wheeling': 1, 'blown': 1, 'sky': 1, 'voice': 1, 'protesting': 2, 'think': 1, 'appear': 1, 'high': 1, 'green': 2, 'meadows': 1, 'glowing': 1, 'lit': 1, 'within': 1, 'come': 2, 'one': 2, 'bush': 2, 'berries': 3, 'ripe': 1, 'flies': 1, 'hanging': 1, 'bluegreen': 1, 'bellies': 1, 'wing': 1, 'panes': 1, 'chinese': 1, 'screen': 1, 'honey-feast': 1, 'stunned': 1, 'believe': 1, 'heaven': 1, 'hook': 2, 'bushes': 1, 'thing': 1, 'two': 1, 'hills': 3, 'sudden': 1, 'wind': 1, 'funnels': 1, 'slapping': 1, 'phantom': 1, 'laundry': 1, 'face': 3, 'sweet': 1, 'tasted': 1, 'salt': 1, 'follow': 1, 'sheep': 1, 'path': 1, 'last': 1, 'brings': 1, '’': 1, 'northern': 1, 'orange': 1, 'rock': 1, 'looks': 1, 'great': 1, 'space': 1, 'white': 1, 'pewter': 1, 'lights': 1, 'din': 1, 'like': 1, 'silversmiths': 1, 'beating': 2, 'intractable': 1, 'metal': 1}\n"
     ]
    }
   ],
   "source": [
    "# Let's count word frequencies again as in code line [27]\n",
    "\n",
    "Freq2 = {}\n",
    "\n",
    "for word in cleanPoem:\n",
    "    Freq2[word] = cleanPoem.count(word)\n",
    "\n",
    "print(Freq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blackberrying sylvia plath nobody lane , nothing , nothing blackberries , blackberries either side , though right mainly , blackberry alley , going hooks , sea somewhere end , heaving . blackberries big ball thumb , dumb eyes ebon hedges , fat blue-red juices . squander fingers . asked blood sisterhood ; must love . accommodate milkbottle , flattening sides . overhead go choughs black , cacophonous flocks— bits burnt paper wheeling blown sky . voice , protesting , protesting . think sea appear . high , green meadows glowing , lit within . come one bush berries ripe bush flies , hanging bluegreen bellies wing panes chinese screen . honey-feast berries stunned ; believe heaven . one hook , berries bushes end . thing come sea . two hills sudden wind funnels , slapping phantom laundry face . hills green sweet tasted salt . follow sheep path . last hook brings hills ’ northern face , face orange rock looks nothing , nothing great space white pewter lights , din like silversmiths beating beating intractable metal .'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's put a list of strings back into one long string with join() method\n",
    "\n",
    "cleanPoem2 = ' '.join(cleanPoem)\n",
    "\n",
    "cleanPoem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last week we also used count() to count how many times a specific word occurs in strings (text) \n",
    "\n",
    "cleanPoem2.count('face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('accommodate', 'milkbottle'), ('asked', 'blood'), ('ball', 'thumb'), ('believe', 'heaven'), ('bellies', 'wing'), ('big', 'ball'), ('bits', 'burnt'), ('blackberry', 'alley'), ('blackberrying', 'sylvia'), ('blood', 'sisterhood'), ('blown', 'sky'), ('blue-red', 'juices'), ('bluegreen', 'bellies'), ('burnt', 'paper'), ('cacophonous', 'flocks—'), ('chinese', 'screen'), ('choughs', 'black'), ('din', 'like'), ('dumb', 'eyes'), ('ebon', 'hedges'), ('either', 'side'), ('eyes', 'ebon'), ('fat', 'blue-red'), ('flattening', 'sides'), ('flocks—', 'bits')]\n"
     ]
    }
   ],
   "source": [
    "# To analye the collocational patterns in a text, we need to import the tools from the nltk.collocations package.\n",
    "\n",
    "from nltk.collocations import *\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(word_tokenize(cleanPoem2))\n",
    "\n",
    "bigrams = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "# Return 25 bigrams with the highest PMI (point-wise mutual information) score.\n",
    "\n",
    "# PMI is a statistical measure of association between a word and a class (category).\n",
    "\n",
    "print(finder.nbest(bigrams.pmi, 25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You will find more on NLTK packages, tools and statistical text modelling here:  \n",
    "\n",
    "https://www.nltk.org/book/  \n",
    "http://www.nltk.org/howto/collocations.html  \n",
    "\n",
    "### Or check the electronic book on natural language processing:\n",
    "\n",
    "Bird, S., Klein, E. and Loper, E.(2009) Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit. O’Reilly Media.  \n",
    "http://www.pitt.edu/~naraehan/ling1330/nltk_book.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h2>Over to You</h2><br>\n",
    "\n",
    "<ul><li>Create your own little corpus consisting of three poems written by the same author. Save them in a .txt file and read it in to analyze your corpus with Python.</li>\n",
    "<li>Write the code that cleans the corpus. Explain what you removed and why.</li>\n",
    "<li>For analysis, tokenize words and sentences; count words and sentences; extract collocational pairs (2-grams).</li>\n",
    "</ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
